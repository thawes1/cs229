{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Solution to 3(a) </font>\n",
    "\n",
    "A conditional probability rule that will be repeatedly used: \n",
    "\n",
    "$$P(A|B)P(B) = P(A \\cap B)$$\n",
    "\n",
    "So have $$P(x, y, \\theta) = P(y | x, \\theta)P(x, \\theta).$$\n",
    "\n",
    "Also have $$P(x, y, \\theta) = P(\\theta | x, y)P(x, y).$$\n",
    "\n",
    "Hence, $$P(y | x, \\theta)P(x, \\theta) = P(\\theta | x, y)P(x, y).$$\n",
    "\n",
    "Also, $$P(x, \\theta) = P(\\theta | x)P(x) = P(\\theta)P(x)$$ since question assumes $P(\\theta | x) = P(\\theta).$\n",
    "\n",
    "Substitute this expression for $P(x, \\theta)$ into preceding equation: $$P(y | x, \\theta)P(\\theta)P(x) = P(\\theta | x, y)P(x, y)$$\n",
    "\n",
    "Thus, $$\\argmax_\\theta P(y | x, \\theta)P(\\theta)P(x) = \\argmax_\\theta P(\\theta | x, y)P(x, y).$$\n",
    "\n",
    "We can ignore the parts of the expression that don't depend on $\\theta$: $$\\argmax_\\theta P(y | x, \\theta)P(\\theta) = \\argmax_\\theta P(\\theta | x, y)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Solution to 3(b) </font>\n",
    "\n",
    "\\begin{align*}\n",
    "\\argmax_\\theta P(\\theta | x, y) &= \\argmax_\\theta P(y | x, \\theta)P(\\theta) \\\\\n",
    "&= \\argmax_\\theta \\log P(y | x, \\theta) + \\log P(\\theta) \\\\\n",
    "&= \\argmax_\\theta \\log P(y | x, \\theta) + \\log \\frac{\\exp(-\\frac{1}{2}\\theta^T (\\eta^2I)^{-1} \\theta)}{\\sqrt{(2\\pi)^{n}}|\\det \\Sigma|} \\\\\n",
    "&= \\argmin_\\theta -\\log P(y | x, \\theta) + \\frac{1}{2\\eta^2} \\|\\theta\\|^2 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Solution to 3(c) </font>\n",
    "\n",
    "From previous part, have $$\\theta_{MAP} = \\argmin_\\theta -\\log P(\\vec{y} | X, \\theta) + \\frac{1}{2\\eta^2} \\|\\theta\\|^2.$$\n",
    "\n",
    "Have \n",
    "\\begin{align*}\n",
    "\\log P(y | X, \\theta) &= \\log \\prod_{i=1}^m P(y^{(i)} | x^{(i)}, \\theta) \\\\\n",
    "&= \\sum_{i=1}^m \\log P(y^{(i)} | x^{(i)}, \\theta) \\\\\n",
    "&= \\sum_{i=1}^m \\log \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp \\left( -\\frac{1}{2\\sigma^2} (y^{(i)} - \\theta^T x^{(i)})^2 \\right) \\\\\n",
    "&= -\\frac{m}{2} \\log 2\\pi\\sigma^2 - \\frac{1}{2\\sigma^2} \\sum_{i=1}^m (y^{(i)} - \\theta^T x^{(i)})^2 \\\\\n",
    "&= -\\frac{m}{2} \\log 2\\pi\\sigma^2 - \\frac{1}{2\\sigma^2}\\|X\\theta - y\\|^2 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "On the third line, used the fact that $p(y^{(i)}|x^{(i)}, \\theta) = N(\\theta^T x^{(i)}, \\sigma^2)$, because question specifies $y^{(i)} = \\theta^T x^{(i)} + \\epsilon^{(i)}$ where $\\epsilon^{(i)} \\sim N(0, \\sigma^2)$. Substituting this into the equation at the top of the cell, we get $$\\theta_{MAP} = \\argmin_\\theta \\frac{1}{2\\sigma^2}\\|X\\theta - y\\|^2 + \\frac{1}{2\\eta^2} \\|\\theta\\|^2.$$\n",
    "\n",
    "Since the question asks for a closed form solution to $\\theta_{MAP}$ for this case, we can find it by differentiating the expression above with respect to $\\theta$ and setting the derivative to zero.\n",
    "\n",
    "\\begin{align*}\n",
    "f(\\theta) &= \\frac{1}{2\\sigma^2}\\|X\\theta - y\\|^2 + \\frac{1}{2\\eta^2} \\|\\theta\\|^2 \\\\\n",
    "\\Rightarrow \\frac{\\partial f}{\\partial \\theta_j} &= \\frac{1}{\\sigma^2} \\sum_{i=1}^m (\\theta^T x^{(i)} -  y^{(i)})x^{(i)}_j + \\frac{\\theta_j}{\\eta^2} \\\\\n",
    "\\Rightarrow \\frac{\\partial f}{\\partial \\theta} &= \\frac{1}{\\sigma^2} X^T (X\\theta - y) + \\frac{\\theta}{\\eta^2} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Setting this to zero, we get\n",
    "\n",
    "\\begin{align*}\n",
    "0 = \\frac{1}{\\sigma^2} X^T (X\\theta_{MAP} - y) + \\frac{\\theta_{MAP}}{\\eta^2} \\\\\n",
    "\\Rightarrow \\theta_{MAP} = (X^TX + \\frac{\\sigma^2}{\\eta^2}I)^{-1}X^Ty \n",
    "\\end{align*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Solution to 3(d) </font>\n",
    "\n",
    "The question merely asks to use a Laplace prior instead of a Gaussian prior for $\\theta$, where $\\theta \\sim L(0, bI)$. So \n",
    "\n",
    "\\begin{align*}\n",
    "\\log P(\\theta) &= \\log \\frac{1}{2b}\\exp \\left(\\frac{-\\|\\theta\\|_1}{b}\\right) \\\\\n",
    "&= \\log \\frac{1}{2b} - \\frac{\\|\\theta\\|_1}{b} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The $\\frac{1}{2}\\|X\\theta-y\\|^2$ part in the previously found $\\theta_{MAP} = \\argmin_\\theta \\frac{1}{2 \\sigma^2}\\|X\\theta - y\\|^2$ stays the same because we are still assuming that $y^{(i)} = \\theta^T x^{(i)} + \\epsilon^{(i)}$ where $\\epsilon^{(i)} \\sim N(0, \\sigma^2)$, and the derivation for that part of the expression does not depend on the prior.\n",
    "\n",
    "So the only thing that needs changing is the $\\frac{1}{2\\eta^2} \\|\\theta\\|^2$ part, which should be changed to $\\frac{1}{b} \\|\\theta\\|_1$ as seen above. The sign change comes from the fact that $\\argmax_\\theta \\log P(\\theta) = \\argmin_\\theta -\\log P(\\theta)$.\n",
    "\n",
    "So\n",
    "\n",
    "\\begin{align*}\n",
    "\\theta_{MAP} &= \\argmin_\\theta \\frac{1}{2 \\sigma^2}\\|X\\theta - y\\|^2 + \\frac{1}{b} \\|\\theta\\|_1 \\\\\n",
    "&= \\argmin_\\theta \\|X\\theta - y\\|^2 + \\frac{2\\sigma^2}{b} \\|\\theta\\|_1\n",
    "\\end{align*}\n",
    "\n",
    "Note: in this notebook $\\|\\cdot\\|$ is the $\\ell_2$ norm, and $\\|\\cdot\\|_1$ is the $\\ell_1$ norm. The question uses $|\\cdot|$ to denote $\\ell_1$ norm, but this is confusing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15312389fa51bcb29fe9963781c4ce50a0f51189ba0dc67d71b16946675dd986"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
